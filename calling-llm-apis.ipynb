{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c13f588",
   "metadata": {},
   "source": [
    "# Gemini ve LangChain ile LLM API'larÄ±nÄ± Ã‡aÄŸÄ±rma GiriÅŸ ğŸ¦œğŸ”—\n",
    "\n",
    "Bu notebook'ta LangChain aracÄ±lÄ±ÄŸÄ±yla LLM API'larÄ±nÄ± nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. Ã–rnek olarak Google'Ä±n Gemini API'sÄ±nÄ± kullanacaÄŸÄ±z. Bu notebook'un sonunda, LangChain kullanarak API Ã§aÄŸrÄ±larÄ± yapmayÄ± ve bunu neden yaptÄ±ÄŸÄ±mÄ±zÄ± bileceksiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ce4db",
   "metadata": {},
   "source": [
    "## âš™ï¸ Kurulum\n",
    "\n",
    "ğŸ‘‰ Kurulum aÅŸamasÄ±nda oluÅŸturduÄŸumuz `.env` dosyasÄ±ndaki ortam deÄŸiÅŸkenlerini yÃ¼klemek iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70069795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:54:29.586547Z",
     "iopub.status.busy": "2026-02-03T20:54:29.585880Z",
     "iopub.status.idle": "2026-02-03T20:54:29.609034Z",
     "shell.execute_reply": "2026-02-03T20:54:29.608511Z",
     "shell.execute_reply.started": "2026-02-03T20:54:29.586519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95c083",
   "metadata": {},
   "source": [
    "ğŸ‘‰ HÃ¼crenin Ã§Ä±ktÄ±sÄ± \"`True`\" mu? Harika! ArtÄ±k Gemini API ile kimlik doÄŸrulamasÄ± yapmak iÃ§in kullanÄ±lacak bir `GOOGLE_API_KEY` ortam deÄŸiÅŸkeni kurmuÅŸ olduk.\n",
    "\n",
    "EÄŸer deÄŸilse, yardÄ±m isteyin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24465d53",
   "metadata": {},
   "source": [
    "## Basit Bir API Ã‡aÄŸrÄ±sÄ± Yapma\n",
    "\n",
    "Bu notebook'ta ÅŸunlarÄ±n nasÄ±l yapÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz:\n",
    "1. Google'Ä±n kendi kÃ¼tÃ¼phanesini kullanarak API Ã§aÄŸrÄ±sÄ± yapma.\n",
    "2. AynÄ± iÅŸlemi LangChain kullanarak yapma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89bfc4",
   "metadata": {},
   "source": [
    "## Google Generative AI KÃ¼tÃ¼phanesini Kullanma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cee132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:54:43.425156Z",
     "iopub.status.busy": "2026-02-03T20:54:43.424572Z",
     "iopub.status.idle": "2026-02-03T20:54:44.229458Z",
     "shell.execute_reply": "2026-02-03T20:54:44.228994Z",
     "shell.execute_reply.started": "2026-02-03T20:54:43.425126Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46771291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:54:57.086132Z",
     "iopub.status.busy": "2026-02-03T20:54:57.085727Z",
     "iopub.status.idle": "2026-02-03T20:54:57.948004Z",
     "shell.execute_reply": "2026-02-03T20:54:57.946878Z",
     "shell.execute_reply.started": "2026-02-03T20:54:57.086087Z"
    }
   },
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"What is the capital of France?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09712465",
   "metadata": {},
   "source": [
    "`response` nesnesine bir gÃ¶z atalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978ae758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:55:00.537218Z",
     "iopub.status.busy": "2026-02-03T20:55:00.536921Z",
     "iopub.status.idle": "2026-02-03T20:55:00.542123Z",
     "shell.execute_reply": "2026-02-03T20:55:00.541504Z",
     "shell.execute_reply.started": "2026-02-03T20:55:00.537197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b5b714",
   "metadata": {},
   "source": [
    "GerÃ§ek cevabÄ± nasÄ±l alabileceÄŸinizi gÃ¶rÃ¼yor musunuz?\n",
    "\n",
    "Neyse ki, cevabÄ± hemen almak iÃ§in sadece `.text` Ã¶zelliÄŸini kullanabiliriz. Deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00c933b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:55:09.816991Z",
     "iopub.status.busy": "2026-02-03T20:55:09.816700Z",
     "iopub.status.idle": "2026-02-03T20:55:09.821586Z",
     "shell.execute_reply": "2026-02-03T20:55:09.821096Z",
     "shell.execute_reply.started": "2026-02-03T20:55:09.816971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7725ea",
   "metadata": {},
   "source": [
    "Gemini cevaplarÄ±nÄ± Markdown formatÄ±nda dÃ¶ndÃ¼rÃ¼r. Bunu kullanalÄ±m!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dafacff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:55:34.586202Z",
     "iopub.status.busy": "2026-02-03T20:55:34.585688Z",
     "iopub.status.idle": "2026-02-03T20:55:34.590623Z",
     "shell.execute_reply": "2026-02-03T20:55:34.590084Z",
     "shell.execute_reply.started": "2026-02-03T20:55:34.586179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is **Paris**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa58345",
   "metadata": {},
   "source": [
    "OluÅŸturma parametrelerini de deÄŸiÅŸtirebilirsiniz. `google.genai` kullanarak bunu ÅŸu ÅŸekilde yaparsÄ±nÄ±z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accf7322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:56:07.126199Z",
     "iopub.status.busy": "2026-02-03T20:56:07.125784Z",
     "iopub.status.idle": "2026-02-03T20:56:08.467943Z",
     "shell.execute_reply": "2026-02-03T20:56:08.466650Z",
     "shell.execute_reply.started": "2026-02-03T20:56:07.126175Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types # We need to import types for the config\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"Write a social media post about how much you're learning about transformers.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=200,\n",
    "        temperature=1.0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033bc800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T20:56:14.110124Z",
     "iopub.status.busy": "2026-02-03T20:56:14.109780Z",
     "iopub.status.idle": "2026-02-03T20:56:14.114840Z",
     "shell.execute_reply": "2026-02-03T20:56:14.114262Z",
     "shell.execute_reply.started": "2026-02-03T20:56:14.110101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few options for a social media post about learning about transformers, ranging in tone and focus. Choose the one that best fits your style!\n",
       "\n",
       "**Option 1: Enthusiastic & Broad**\n",
       "\n",
       "> My brain is officially buzzing with transformers! ğŸ¤¯ From the self-attention mechanism to the encoder-decoder architecture, I'm absolutely fascinated by how these models work and the incredible things they can do. It's like unlocking a new superpower in the world of AI! So much to learn, so little time! #Transformers #AI #MachineLearning #DeepLearning #TechLearning #NLP\n",
       "\n",
       "**Option 2: Slightly More Technical & Focused**\n",
       "\n",
       "> Diving deep into the world of transformer models lately! ğŸ¤“ Really starting to wrap my head around concepts like positional encodings, multi-head attention, and why they've revolutionized NLP. It's a challenging but incredibly rewarding journey. Excited to see where this knowledge takes me! #TransformersAI #AttentionIsAll"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc6abf",
   "metadata": {},
   "source": [
    "Harika. Ancak baÅŸka bir API denemek istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n, Ã¶rneÄŸin OpenAI'nin veya Anthropic'in?\n",
    "\n",
    "OnlarÄ±n dokÃ¼mantasyonlarÄ±nÄ± incelemek ve tÃ¼m kodunuzu onlarÄ±n API'sini kullanacak ÅŸekilde yeniden yazmak zorunda kalÄ±rsÄ±nÄ±z. Tabii ki benzer olacaktÄ±r, ancak aynÄ± olmayacaktÄ±r.\n",
    "\n",
    "Neyse ki LangChain var!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2e26e",
   "metadata": {},
   "source": [
    "## LangChain Kullanma ğŸ¦œğŸ”—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54bacb",
   "metadata": {},
   "source": [
    "Neden LangChain kullanÄ±rsÄ±nÄ±z?\n",
    "\n",
    "1. **Model-BaÄŸÄ±msÄ±z Kod**\n",
    "\n",
    "   LangChain, farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± (Google, OpenAI, Anthropic, vb.) arasÄ±nda minimal kod deÄŸiÅŸikliÄŸi ile geÃ§iÅŸ yapmanÄ±zÄ± saÄŸlayan soyutlamalar sunar. Google API'sine doÄŸrudan kod yazarsanÄ±z, saÄŸlayÄ±cÄ± deÄŸiÅŸtirmek Ã¶nemli Ã¶lÃ§Ã¼de yeniden dÃ¼zenleme gerektirir.\n",
    "\n",
    "2. **BirleÅŸik ArayÃ¼z**\n",
    "\n",
    "   LangChain, altta yatan API'den baÄŸÄ±msÄ±z olarak farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± arasÄ±nda etkileÅŸimleri standartlaÅŸtÄ±rÄ±r ve tutarlÄ± yÃ¶ntemler ile yanÄ±t formatlarÄ± sunar.\n",
    "\n",
    "3. **BileÅŸenlerle Ã‡alÄ±ÅŸabilirlik**\n",
    "\n",
    "   LangChain'in zincir ve pipeline mimarisi, tÃ¼m alt yapÄ±yÄ± kendiniz halletmeden prompt, bellek ve eriÅŸim sistemlerini birleÅŸtiren karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± oluÅŸturmayÄ± kolaylaÅŸtÄ±rÄ±r.\n",
    "\n",
    "4. **YerleÅŸik AraÃ§lar**\n",
    "\n",
    "   LangChain, Ã§Ä±ktÄ± ayrÄ±ÅŸtÄ±rma, prompt ÅŸablonlarÄ± ve kendiniz uygulamanÄ±z gereken diÄŸer yardÄ±mcÄ± araÃ§larÄ± iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8cf3a",
   "metadata": {},
   "source": [
    "[LangChain'in chat entegrasyonlarÄ± listesi](https://docs.langchain.com/oss/python/integrations/chat)'ne gidin ve entegrasyon listesine bakÄ±n. Favori LLM saÄŸlayÄ±cÄ±nÄ±zÄ± bulabiliyor musunuz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360a3ae",
   "metadata": {},
   "source": [
    "Kodumuzda `chat_models.ChatGoogleGenerativeAI` kullanmak istemiyoruz Ã§Ã¼nkÃ¼ bu Ã¶zellikle Gemini iÃ§in yapÄ±lmÄ±ÅŸ. LLM'yi deÄŸiÅŸtirmek istersek, modeli baÅŸlatma ÅŸeklimizi deÄŸiÅŸtirmek zorunda kalÄ±rÄ±z. Neyse ki LangChain bir modeli baÅŸlatmak iÃ§in daha genel bir yol sunar.\n",
    "\n",
    "Gemini'yi tekrar kullanalÄ±m, ancak ÅŸimdi LangChain'in genel Chat Models'ini kullanarak.\n",
    "\n",
    "ğŸ‘‰ [LangChain'in \"Models\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/models) sayfasÄ±na gidin ve Gemini kullanarak bir chat modelinin nasÄ±l baÅŸlatÄ±lacaÄŸÄ±nÄ± bulun.\n",
    "\n",
    "Ä°puÃ§larÄ±:\n",
    "1. Hemen \"Basic Usage\" bÃ¶lÃ¼mÃ¼ne gidin.\n",
    "2. Kullanmak istediÄŸiniz modeli seÃ§erek doÄŸru dokÃ¼mantasyonu hemen gÃ¶rebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed55ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:01:45.939065Z",
     "iopub.status.busy": "2026-02-03T21:01:45.938382Z",
     "iopub.status.idle": "2026-02-03T21:01:46.305124Z",
     "shell.execute_reply": "2026-02-03T21:01:46.304634Z",
     "shell.execute_reply.started": "2026-02-03T21:01:45.939038Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash-lite\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1da678",
   "metadata": {},
   "source": [
    "Modelin en temel kullanÄ±mÄ± sadece `.invoke()` metodunu kullanmaktÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9afdfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:02:18.092307Z",
     "iopub.status.busy": "2026-02-03T21:02:18.091356Z",
     "iopub.status.idle": "2026-02-03T21:02:18.832965Z",
     "shell.execute_reply": "2026-02-03T21:02:18.831556Z",
     "shell.execute_reply.started": "2026-02-03T21:02:18.092282Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "response = model.invoke(\"What is the capital of France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16afa0b",
   "metadata": {},
   "source": [
    "YanÄ±ta bir gÃ¶z atalÄ±m. Nesnenin tÃ¼m Ã¶znitelik ve metodlarÄ±nÄ± iÃ§eren `__dict__`'ini gÃ¼zel ÅŸekilde yazdÄ±rmak iÃ§in `pprint()` kullanÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60844d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:02:38.450040Z",
     "iopub.status.busy": "2026-02-03T21:02:38.449731Z",
     "iopub.status.idle": "2026-02-03T21:02:38.455404Z",
     "shell.execute_reply": "2026-02-03T21:02:38.454732Z",
     "shell.execute_reply.started": "2026-02-03T21:02:38.450019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_kwargs': {},\n",
      " 'content': 'The capital of France is **Paris**.',\n",
      " 'id': 'lc_run--019c2550-2fed-7b80-9e5b-7424157f37a8-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'STOP',\n",
      "                       'model_name': 'gemini-2.5-flash-lite',\n",
      "                       'model_provider': 'google_genai',\n",
      "                       'safety_ratings': []},\n",
      " 'tool_calls': [],\n",
      " 'type': 'ai',\n",
      " 'usage_metadata': {'input_token_details': {'cache_read': 0},\n",
      "                    'input_tokens': 6,\n",
      "                    'output_tokens': 8,\n",
      "                    'total_tokens': 14}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceeb7b0",
   "metadata": {},
   "source": [
    "CevabÄ± Ã§Ä±karÄ±n ve gÃ¶rÃ¼ntÃ¼leyin. Markdown formatÄ±nda olduÄŸunu unutmayÄ±n, bu yÃ¼zden gÃ¼zel gÃ¶rÃ¼nmesini saÄŸlayabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1d4758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:02:59.566627Z",
     "iopub.status.busy": "2026-02-03T21:02:59.565804Z",
     "iopub.status.idle": "2026-02-03T21:02:59.571267Z",
     "shell.execute_reply": "2026-02-03T21:02:59.570705Z",
     "shell.execute_reply.started": "2026-02-03T21:02:59.566603Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is **Paris**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ccff71",
   "metadata": {},
   "source": [
    "Modelin temperature deÄŸerini `.temperature` Ã¶zniteliÄŸine eriÅŸerek kontrol edebilirsiniz. Deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4744a3d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:03:54.030883Z",
     "iopub.status.busy": "2026-02-03T21:03:54.030342Z",
     "iopub.status.idle": "2026-02-03T21:03:54.035268Z",
     "shell.execute_reply": "2026-02-03T21:03:54.034763Z",
     "shell.execute_reply.started": "2026-02-03T21:03:54.030861Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.temperature, model.max_output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c314ca",
   "metadata": {},
   "source": [
    "Modeli kullanmadan Ã¶nce, Ã¶zniteliklere yeni deÄŸerler atayarak oluÅŸturma parametrelerini de ayarlayabiliriz.\n",
    "\n",
    "Daha Ã¶nce Google'Ä±n kÃ¼tÃ¼phanesini kullanarak sosyal medya gÃ¶nderisi yazmak iÃ§in yaptÄ±ÄŸÄ±mÄ±zÄ±n eÅŸdeÄŸerini kodlamaya Ã§alÄ±ÅŸÄ±n.\n",
    "\n",
    "> _Not_: Normal olarak modelin `max_output_tokens` deÄŸerini ayarlayabilmemiz gerekir (modeli baÅŸlatÄ±rken veya daha sonra Ã¶zniteliÄŸi deÄŸiÅŸtirerek). _langchain_google_genai_'nin mevcut sÃ¼rÃ¼mÃ¼ (4.1.1) bir [hataya](https://github.com/langchain-ai/langchain-google/issues/1454) sahip ve bu Ã§alÄ±ÅŸmÄ±yor. GeÃ§ici Ã§Ã¶zÃ¼m? `max_output_tokens`'Ä± `.invoke()` metodunun bir parametresi olarak ayarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd36137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:06:13.410561Z",
     "iopub.status.busy": "2026-02-03T21:06:13.409495Z",
     "iopub.status.idle": "2026-02-03T21:06:15.940153Z",
     "shell.execute_reply": "2026-02-03T21:06:15.939684Z",
     "shell.execute_reply.started": "2026-02-03T21:06:13.410530Z"
    },
    "tags": [
     "steps"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few options for a social media post about learning about transformers, with slightly different tones. Choose the one that best fits your style!\n",
       "\n",
       "**Option 1: Enthusiastic & Slightly Technical**\n",
       "\n",
       "> Dive headfirst into the world of AI and guess what's blowing my mind? âœ¨ **Transformers!** ğŸ¤¯ Seriously, the architecture behind these models is a game-changer. I'm deep in the rabbit hole of attention mechanisms, positional encoding, and encoder-decoder stacks. The ability to process sequential data like this is revolutionary. So much to learn, but loving every minute! #AI #MachineLearning #DeepLearning #Transformers #NLP #Tech\n",
       "\n",
       "**Option 2: Casual & Wonderstruck**\n",
       "\n",
       "> My brain is officially buzzing with new knowledge! ğŸ§  I've been spending a lot of time learning about **Transformers**, and WOW. It's like unlocking a new level of understanding for how AI processes language and so much more. Mind officially blown by the elegance of these models. Can't wait to see what else I discover! ğŸ¤“ #Learning #AI #TechJourney #TransformersModel #FutureTech\n",
       "\n",
       "**Option 3: Focused on Application & Impact**\n",
       "\n",
       "> Lately, I've been fascinated by the power of **Transformers** in AI. From generating creative text to understanding complex queries, their impact is undeniable. ğŸš€ I'm really enjoying diving into the intricacies of their design and how they're reshaping fields like Natural Language Processing. So much potential! #ArtificialIntelligence #MachineLearning #TransformersAI #Innovation #TechTrends\n",
       "\n",
       "**Option 4: Short & Sweet**\n",
       "\n",
       "> Officially on a deep dive into **Transformers** and my mind is expanding! ğŸ¤¯ So much to absorb, so much to learn. #AI #Transformers #Learning\n",
       "\n",
       "**Remember to also consider adding:**\n",
       "\n",
       "*   **A relevant image or GIF:** A brain graphic, a circuit board, a futuristic image, or even a relevant meme can make your post more engaging.\n",
       "*   **A question to encourage interaction:** \"What's the most mind-blowing thing you've learned about AI recently?\" or \"Any favorite resources for learning about Transformers?\"\n",
       "\n",
       "Choose the one that feels most authentic to you and happy learning!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the maximum number of output tokens to 200\n",
    "\n",
    "model.max_output_tokens = 200\n",
    "\n",
    "# Set the temperature to 1.0\n",
    "\n",
    "model.temperature = 1.0\n",
    "\n",
    "# Generate a response with the new settings\n",
    "\n",
    "response = model.invoke(\"Write a social media post about how much you're learning about transformers\")\n",
    "\n",
    "# Display the response\n",
    "\n",
    "Markdown(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d459e56",
   "metadata": {},
   "source": [
    "Bunun avantajÄ±? Bu LangChain Chat Model birÃ§ok baÅŸka API'yi destekleyebilir.\n",
    "\n",
    "BaÅŸka bir modele geÃ§mek iÃ§in deÄŸiÅŸtirmeniz gereken tek ÅŸeyler:\n",
    "1. DiÄŸer model iÃ§in bir API anahtarÄ± alÄ±n ve kodunuzda tanÄ±mlayÄ±n.\n",
    "2. Modeli baÅŸlatÄ±rken model ve saÄŸlayÄ±cÄ±yÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb3714",
   "metadata": {},
   "source": [
    "### Ã‡oklu Mesajlar\n",
    "\n",
    "`.invoke()` fonksiyonunu sadece tek bir mesajla kullanmak biraz kÄ±sÄ±tlayÄ±cÄ±.\n",
    "\n",
    "Åu gibi birden fazla mesaj saÄŸlayabilirsiniz:\n",
    "- `SystemMessage` veya sistem mesajlarÄ±: modelin nasÄ±l davranacaÄŸÄ±nÄ± sÃ¶ylemek iÃ§in\n",
    "- `HumanMessage` veya KullanÄ±cÄ± mesajlarÄ±: kullanÄ±cÄ±dan gelen girdi\n",
    "- `AIMessage` veya Asistan mesajlarÄ±: modelden gelen yanÄ±t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400445a",
   "metadata": {},
   "source": [
    "Bir sosyal medya yazarÄ± yapalÄ±m.\n",
    "\n",
    "Modele nasÄ±l davranacaÄŸÄ±nÄ± aÃ§Ä±klayan bir sistem mesajÄ± gÃ¶ndereceÄŸiz. Sonra kullanÄ±cÄ± mesajÄ±nda, kendimizi sadece yazacaÄŸÄ± konuyu vermekle sÄ±nÄ±rlayabiliriz.\n",
    "\n",
    "Bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenmek iÃ§in [LangChain'in \"Messages\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/messages)'na bakÄ±n.\n",
    "\n",
    "Sistem mesajÄ± iÃ§in ilhama mÄ± ihtiyacÄ±nÄ±z var? Ä°ÅŸte baÅŸlamanÄ±z iÃ§in temel bir talimat:\n",
    "\n",
    "```python\n",
    "\"\"\"Sen Ãœretken AI Ã¶ÄŸrencisi iÃ§in gÃ¶nderiler yazan yaratÄ±cÄ± bir sosyal medya yazarÄ±sÄ±n.\n",
    "GÃ¶nderilerinde her zaman kelime oyunu ve harekete geÃ§irici Ã§aÄŸrÄ± bulunur.\n",
    "GÃ¶nderilerin maksimum 200 karakter uzunluÄŸundadÄ±r.\n",
    "Her zaman emoji kullanÄ±rsÄ±n.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2952f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:09:12.211221Z",
     "iopub.status.busy": "2026-02-03T21:09:12.210709Z",
     "iopub.status.idle": "2026-02-03T21:09:12.990575Z",
     "shell.execute_reply": "2026-02-03T21:09:12.989836Z",
     "shell.execute_reply.started": "2026-02-03T21:09:12.211203Z"
    },
    "tags": [
     "steps"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Get ready to be **transformed**! ğŸ¤– Dive into the amazing world of transformers and unlock your AI potential. ğŸš€ What will you build first? âœ¨ #AI #Transformers #Tech"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary classes\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Create a list of messages\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        \"\"\"You are a creative social media writer writing posts for a Gen AI student.\n",
    "        Your posts always include a pun, and a call to action.\n",
    "        Your posts are maximum 200 characters long.\n",
    "        You always use emojis.\n",
    "        \"\"\"\n",
    "        ),\n",
    "    HumanMessage(\"I'm learning about transformers.\"),\n",
    "]\n",
    "\n",
    "# Generate a response using the list of messages\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# Display the response\n",
    "\n",
    "Markdown(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b4772",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! ArtÄ±k LangChain kullanarak Ã§oklu mesajlarla temel prompt yazma konusunda uzmanlaÅŸtÄ±nÄ±z."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
